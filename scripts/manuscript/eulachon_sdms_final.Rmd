---
title: "Eulachon eDNA SDMs"
author: "Owen R. Liu"
date: "2025-01-09"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
options(dplyr.summarise.inform=FALSE)
library(tidyverse)
library(here)
library(tictoc)
library(sf)
library(viridis)
library(ggsci)
library(cowplot)
library(rnaturalearth)
library(marmap)
library(RANN)
library(contoureR)
library(sdmTMB)
library(nngeo)
library(contoureR)
library(corrplot)
```

# Purpose

Build species distribution models in `sdmTMB` for eulachon, based on spatiotemporal data on eDNA for eulachon (*Thaleichthys pacificus*). The data are structured in three dimensions (latitude, longitude, depth), or four including year, and so we want to build a flexible set of models that can take advantage of this dimensionality of the data to create high-resolution predictions.

We will use environmental covariates to constrain our predictions, based on temperature, salinity, and bottom depth, as well as biological productivity variables. In spatiotemporal models, though, we also need to decide how to guide the model to partition variation across different spatial and depth fields (i.e., the spatially autocorrelated parts of the model that are estimated in parallel to the fitted covariates). To explore these options, we decided to try models with different combinations of spatial fields and intercepts:

Spatial field options to try: 

*   One common spatial field across all data
*   spatial field by depth
*   spatial field by year
*   spatial field by depth and year

Intercepts options to try

*   single intercept
*   random intercept by depth category
*   random intercept by year
*   random intercept by depth and year

Combinations of spatial fields and intercepts gives us 16 models to consider. Some of these models will certainly break and/or not converge, particularly the more complex versions.

# Pre-processing

Import eDNA and covariate data, designate offsets, and build prediction grid. Note that cleaning and joining of the standards and unknown samples has been done in other scripts---one to process the 2019 data, one for 2021, and one to join them. If desired, you can re-run those here, but they are not evaluated out for now to save time.

```{r,eval=F,warning=F,message=F}
rmarkdown::render('process 2019 eulachon data.Rmd',quiet=TRUE)
rmarkdown::render('process 2021 eulachon data.Rmd',quiet=TRUE)
source('join_eulachon_qPCR_data.R')

rm(list=ls())
```

## Import Data

Spatial coordinate reference system we will use for thesse analyses:

```{r}
pred.crs <- terra::rast(here('data','raster_grid','fivekm_grid.tif')) %>% st_crs()
```

Load in our cleaned and joined eDNA data.

```{r}
# qPCR standards
d <- read_rds(here('data','qPCR',"eulachon qPCR 2019 and 2021 standards clean.rds")) %>% 
  mutate(Ct=replace_na(Ct,0))# delta-models in sdmTMB need this

# field samples (already joined to physical GLORYS data)
d_obs <- read_rds(here('data','eDNA_glorys_matched.rds'))
d_obs_bgc <- read_rds(here('data','eDNA_glorys_bgc_matched.rds')) %>% 
  dplyr::select(chl:phyc)

# river influence variable, already matched to eDNA
river_metric <- read_rds(here('data','eDNA_river_influence_matched.rds')) %>% 
  dplyr::select(river_input)

# join the covariates
d_obs <- d_obs %>% 
  bind_cols(d_obs_bgc) %>%
  bind_cols(river_metric) %>% 
  mutate(Ct=replace_na(Ct,0)) %>% # delta-models in sdmTMB need this (no NAs)
  mutate(utm.lon.km=utm.lon.m/1000,
         utm.lat.km=utm.lat.m/1000)

# positive samples by depth/year
d_obs %>% 
  filter(Ct>0) %>% 
  count(year,depth_cat) %>% 
  ggplot(aes(depth_cat,n,fill=factor(year)))+
  labs(x="Depth Category",y="Number of Positive Observations",fill="Year")+
  geom_col(position='dodge')

# table of samples by depth/year
obs_tbl <- d_obs %>% 
  mutate(amp=ifelse(Ct>0,"Amplified","Did not amplify")) %>% 
  # filter(depth_cat %in% c(0,50,150)) %>%
  mutate(depth_cat=factor(depth_cat)) %>% 
  count(year,depth_cat,amp)

# positive samples by depth/year
d_obs %>% 
  mutate(amp=ifelse(Ct>0,"Amplified","Did not amplify")) %>% 
  # filter(depth_cat %in% c(0,50,150)) %>% 
  mutate(depth_cat=factor(depth_cat)) %>% 
  count(year,depth_cat,amp) %>% 
  ggplot(aes(depth_cat,n,fill=factor(amp)))+
  labs(x="Depth Category",y="Number of Samples",fill="Amplified?")+
  facet_wrap(~year,nrow=1)+
  scale_fill_manual(values=PNWColors::pnw_palette("Starfish",2))+
  geom_col()+theme(axis.text=element_text(size=12),axis.title = element_text(size=12))

# field samples, filtered such that we are only including depth categories 0 (surface), 50m, and 150m
d_obs_filt <- d_obs %>% filter(depth_cat %in% c(0,50,150)) 

# %>% 
#   # what if we decide to use only samples with spatial coverage in both years? Basically all samples north of 37.5
#   filter(lat>37.5)

d_obs_sf <- d_obs_filt %>% st_as_sf(coords=c('utm.lon.m','utm.lat.m'),crs=pred.crs)
```

## Covariate data

Bathymetry/bottom depth was already attached to the samples during pre-processing. The field samples were also joined to modeled GLORYS data from their [Global Ocean Physics Reanalysis](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/description). See scripts `match_GLORYS_temp_salinity.R` and `match_GLORYS_bgc.R`.

### Krill/Euphausiid data

These data on the relative abundance of krill come from Beth Phillips, and are organized in the script `krill_nasc_matching`. As with the raw data cleaning above, we do not evaluate this chunk here and just use the output; but the user can run it if they wish. Be warned that it will take awhile to run.

```{r,eval=F}
rmarkdown::render(here::here('krill data construction.Rmd'),quiet=TRUE)
```

```{r}
# Load krill data
edna_krill_metrics <- read_rds(here('data','krill','edna_krill_metrics.rds')) %>% 
  filter(depth_cat %in% c(0,50,150))
  
d_obs_filt <- d_obs_filt %>% bind_cols(edna_krill_metrics %>% dplyr::select(k1:k6))
```

### River discharge data

We also have a dataset of mean river discharge for US West Coast rivers, which we have projected onto our ocean model grid using exponential distance weighting (see script `river_discharge`). Basically, this allows us to explore a variable representing the distance of each spatial grid cell to river mouths, weighted by distance between river and grid cell, as well as by the magnitude of annual discharge from the river.

```{r}
river_mean_discharge <- read_rds(here('data','rivers_mean_discharge_MarMay.rds')) # mean March to May discharge for each west coast river
riverine_influence <- read_rds(here('data','river_influence_grid_matched.rds')) # grid matched
```

## Log Covariates

Natural logging covariates to scale them better for model fitting

```{r}
#log covariates
d_obs_filt <- d_obs_filt %>% 
  # make bottom depth positive
  mutate(bathy.bottom.depth=-bathy.bottom.depth) %>% 
  # log covariates
  mutate(across(c(so,thetao,bathy.bottom.depth,k1,k2,k3,k4,k5,k6,chl,no3,nppv,o2,phyc,river_input),list(ln=function(x){
    x[x==0]<-1
    log(x)
    })))
```

```{r}
logged_vars_p <- d_obs_filt %>% 
  select(contains("_ln")) %>% 
  pivot_longer(everything(),names_to="variable",values_to="val") %>% 
  ggplot(aes(val,fill=variable))+
  geom_density()+
  facet_wrap(~variable,scales='free')
logged_vars_p
```

## Other Transformations

Here we add some other transformations of the above variables in case we want to try them in fitting

```{r}
d_obs_filt <- d_obs_filt %>% 
  # squares
  mutate(depth_ln2=bathy.bottom.depth_ln^2) %>% 
  mutate(thetao_ln2=thetao_ln^2,
         so_ln2=so_ln^2)

# defining factors for depth category and year
d_obs_filt$depth_cat <- factor(d_obs_filt$depth_cat)

d_obs_filt$yr_fct <- as.factor(d_obs_filt$year)
```

Save the full dataset

```{r}
write_rds(d_obs_filt,here::here('data','d_obs_ready_for_sdmTMB.rds'))
```

## INLA Mesh

Create the mesh that will be the basis of our estimation---based on the spatial distribution of our sample data, the mesh is created in order to facilitate efficient processing and estimation of the model in sdmTMB. Instead of calculating enormous covariance matrices in model fitting, we can drastically reduce computation time by using the mesh.

At the bottom of this script under "Test Mesh Complexity", there is a description and plots of this INLA mesh selection exercise, leading us to select the final mesh used for modeling.

```{r}
mesh <- make_mesh(d_obs_filt,xy_cols=c('utm.lon.km','utm.lat.km'),type='cutoff',cutoff=40)

png(here('plots','selected_inla_mesh.png'),w=480,h=800,bg="transparent")
plot(mesh)
dev.off()
```

Now, with covariate data prepared and the model mesh created, we are ready to start fitting models. We do this in two stages: first, we compare model structures to pick an appropriate structural format for sdmTMB given our data. Then, we use variations on our chosen model to select appropriate environmental covariates and create the most parsimonious final model.

# Fit Models

In the first stage of model selection, we decide on an appropriate model structure, referring to our choices about specifications of intercepts and type of latent spatial field. All models in this initial stage will include a spatial field of some flavor, as well as penalized splines for temperature and depth covariates. They will vary structurally in the specification of the spatial field(s) and the types of offsets/intercepts we impose.

Spatial field options to try: 

*   One common spatial field across all data
*   spatial field by depth
*   spatial field by year
*   spatial field by depth and year

Intercepts options to try

*   single intercept
*   random intercept by depth category
*   random intercept by year
*   random intercept by depth and year

We will do this one at a time, increasing slowly in complexity. In the second stage, we try different environmental covariates

As a measure of model fit, we use cross-validation, with 10% of the data randomly withheld as a test set, and the rest used for training the model. Using the same cross-validation folds across all candidate models, we can pull the summed log likelihood from cross-validation as a measure of model skill.

## Cross Validation Folds

```{r}
# just for reproducibility, manually set the RNG seed
set.seed(8913)

# create the folds in the data, where 10% are assigned to the test set
clust <-sample(seq_len(2), size = nrow(d_obs_filt), replace = TRUE,prob = c(0.1,0.9))

```


```{r}
# source the plotting utilities/helpers
source(here("scripts","plotting_utils.R"))
```


## Common Spatial Field

Fit 0 is an intercept-only model with a spatial field but no environmental covariates.

```{r}
tic("Fitting:")
f0 <- sdmTMB(
  Ct ~ 1+washed,
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatiotemporal = "off",
  time=NULL,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
f0
paste("AIC:",AIC(f0))
make_pred_obs_plots(f0,d,model_name="Fit0")

tic("Calculating cross-validation:")
f0_cv <- sdmTMB_cv(
  Ct ~ 1+washed,
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  fold_ids=clust,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
paste("CVLL:",f0_cv$fold_loglik[[1]])
```

Fit 1 is a model with just one common spatial field, a single intercept, and one covariate (log temperature).

```{r}
tic("Fitting:")
f1 <- sdmTMB(
  Ct ~ 1+s(thetao_ln,k=3)+washed,
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatiotemporal = "off",
  time=NULL,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
f1
paste("AIC:",AIC(f1))
make_pred_obs_plots(f1,d,model_name="Fit1")

tic("Calculating cross-validation:")
f1_cv <- sdmTMB_cv(
  Ct ~ 1+s(thetao_ln,k=3)+washed,
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  fold_ids=clust,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
paste("CVLL:",f1_cv$fold_loglik[[1]])
```

Fit 2 includes one spatial field, with random intercepts by depth category.

```{r}
tic("Fitting:")
f2 <- sdmTMB(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|depth_cat),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatiotemporal = "off",
  time=NULL,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
f2
paste("AIC:",AIC(f2))
make_pred_obs_plots(f2,d,model_name="Fit2")

tic("Calculating cross-validation:")
f2_cv <- sdmTMB_cv(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|depth_cat),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  fold_ids=clust,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()

paste("CVLL:",f2_cv$fold_loglik[[1]])

```

Fit 3 includes one spatial field and random intercept by year.

```{r}
tic("Fitting:")
f3 <- sdmTMB(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|yr_fct),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatiotemporal = "off",
  time=NULL,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
f3
paste("AIC:",AIC(f3))
make_pred_obs_plots(f3,d,model_name="Fit3")

tic("Calculating cross-validation:")
f3_cv <- sdmTMB_cv(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|yr_fct),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  fold_ids=clust,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
paste("CVLL:",f3_cv$fold_loglik[[1]])
```

Fit 4 includes one spatial field with random intercepts by year and depth category

```{r}
tic("Fitting:")
f4 <- sdmTMB(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|yr_fct)+(1|depth_cat),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatiotemporal = "off",
  time=NULL,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
f4
paste("AIC:",AIC(f4))
make_pred_obs_plots(f4,d,model_name="Fit4")

tic("Calculating cross-validation:")
f4_cv <- sdmTMB_cv(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|yr_fct)+(1|depth_cat),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  fold_ids=clust,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
paste("CVLL:",f4_cv$fold_loglik[[1]])
```

## Spatial Field by Depth

Fit 5 includes spatial fields by depth category, but a single intercept.

```{r}
# make dummy factors for depth categories
m <- model.matrix(Ct ~ depth_cat, data = d_obs_filt)
d_obs_filt$d1 <- m[,1]
d_obs_filt$d2 <- m[,2]
d_obs_filt$d3 <- m[,3]
```
 
```{r}
tic("Fitting:")
f5 <- sdmTMB(
  Ct ~ 1+s(thetao_ln,k=3)+washed,
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatiotemporal = "off",
  spatial_varying= ~d1+d2+d3,
  time=NULL,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
f5
paste("AIC:",AIC(f5))
make_pred_obs_plots(f5,d,model_name="Fit5")

tic("Calculating cross-validation:")
f5_cv <- sdmTMB_cv(
  Ct ~ 1+s(thetao_ln,k=3)+washed,
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatial_varying= ~d1+d2+d3,
  fold_ids=clust,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc() 
paste("CVLL:",f5_cv$fold_loglik[[1]])
```

Fit 6 includes spatial fields by depth category, and random intercepts by depth category.

```{r}
tic("Fitting:")
f6 <- sdmTMB(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|depth_cat),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatiotemporal = "off",
  spatial_varying= ~d1+d2+d3,
  time=NULL,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
f6
paste("AIC:",AIC(f6))
make_pred_obs_plots(f6,d,model_name="Fit6")

tic("Calculating cross-validation:")
f6_cv <- sdmTMB_cv(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|depth_cat),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatial_varying= ~d1+d2+d3,
  fold_ids=clust,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
paste("CVLL:",f6_cv$fold_loglik[[1]])
```

Fit 7 includes spatial field by depth category, and random intercepts by year.

```{r}
tic("Fitting:")
f7 <- sdmTMB(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|yr_fct),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatiotemporal = "off",
  spatial_varying= ~d1+d2+d3,
  time=NULL,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
f7
paste("AIC:",AIC(f7))
make_pred_obs_plots(f7,d,model_name="Fit7")

tic("Calculating cross-validation:")
f7_cv <- sdmTMB_cv(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|yr_fct),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatial_varying= ~d1+d2+d3,
  fold_ids=clust,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
paste("CVLL:",f7_cv$fold_loglik[[1]])
```


Fit 8 includes spatial fields by depth category, and random intercepts by depth and year

```{r}
tic("Fitting:")
f8 <- sdmTMB(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|yr_fct)+(1|depth_cat),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatiotemporal = "off",
  spatial_varying= ~d1+d2+d3,
  time=NULL,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
f8
paste("AIC:",AIC(f8))
make_pred_obs_plots(f8,d,model_name="Fit8")

tic("Calculating cross-validation:")
f8_cv <- sdmTMB_cv(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|yr_fct)+(1|depth_cat),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatial_varying= ~d1+d2+d3,
  fold_ids=clust,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
paste("CVLL:",f8_cv$fold_loglik[[1]])
```

## Spatial Field by Year

Fit 9 includes spatial fields by year, but a single intercept.

```{r}
tic("Fitting: ")
f9 <- sdmTMB(
  Ct ~ 1+s(thetao_ln,k=3)+washed,
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  time="year",
  spatiotemporal="IID",
  spatial="on",
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
f9

paste("AIC:",AIC(f9))
make_pred_obs_plots(f9,d,model_name="Fit9")

tic("Calculating cross-validation:")
f9_cv <- sdmTMB_cv(
  Ct ~ 1+s(thetao_ln,k=3)+washed,
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  time="year",
  spatiotemporal="IID",
  fold_ids=clust,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
paste("CVLL:",f9_cv$fold_loglik[[1]])
```

Fit 10 includes spatial fields by year, and random intercepts by depth category.

```{r}
tic("Fitting: ")
f10 <- sdmTMB(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|depth_cat),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  time="year",
  spatiotemporal="IID",
  spatial="on",
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
f10

paste("AIC:",AIC(f10))
make_pred_obs_plots(f10,d,model_name="Fit10")

tic("Calculating cross-validation:")
f10_cv <- sdmTMB_cv(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|depth_cat),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  time="year",
  spatiotemporal="IID",
  fold_ids=clust,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
paste("CVLL:",f10_cv$fold_loglik[[1]])
```

Fit 11 includes spatial fields by year, and random intercepts by year.

```{r}
tic("Fitting: ")
f11 <- sdmTMB(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|yr_fct),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  time="year",
  spatiotemporal="IID",
  spatial="on",
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
f11

paste("AIC:",AIC(f11))
make_pred_obs_plots(f11,d,model_name="Fit11")

tic("Calculating cross-validation:")
f11_cv <- sdmTMB_cv(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|yr_fct),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  time="year",
  spatiotemporal="IID",
  fold_ids=clust,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
paste("CVLL:",f11_cv$fold_loglik[[1]])
```

Fit 12 includes spatial fields by year, and random intercepts by depth and year

```{r}
tic("Fitting: ")
f12 <- sdmTMB(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|yr_fct)+(1|depth_cat),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  time="year",
  spatiotemporal="IID",
  spatial="on",
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
f12

paste("AIC:",AIC(f12))
make_pred_obs_plots(f12,d,model_name="Fit12")

tic("Calculating cross-validation:")
f12_cv <- sdmTMB_cv(
  Ct ~ 1+s(thetao_ln,k=3)+washed+(1|yr_fct)+(1|depth_cat),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  time="year",
  spatiotemporal="IID",
  fold_ids=clust,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
paste("CVLL:",f12_cv$fold_loglik[[1]])
```

After fitting all of these candidate models, models 0, 1, 3 and 4 converged with no issues, and relatively quickly, with Models 3 and 4 having the highest log-likelihood of the test set. Models 2, 5, and 6 seemingly had difficulty apportioning variance between the spatial fields and their varying representations of depth (i.e., intercepts or spatial fields by depth). They converged, but with significant warnings (see,e.g., `sanity(f5)`). Models 7-12 did not converge, which is expected to some degree as the models become more complex and the data do not support that level of complexity.

# Variable Selection

Now that we have tested the different model structures, we can choose a preferred model and then try different environmental covariates. We have temperature, depth, salinity, and the various krill metrics. We'll choose three of our highest-likelihood cross-validated fitted models for this exercise, which were Model 1 (single intercept and common spatial field across depths and years) Model 3 (common spatial field, intercept by year), and Model 4 (common spatial field, intercepts by depth category and year).

We use cross-validation again to evaluate whether to include each variable. We try all combinations of temperature, depth, river input, and salinity, but choose only one krill metric.

## Abiotic variables

Make a table of combinations of variables to test in the 3 models.

```{r}
# Formulas to try (with different variables)
vars_to_test <- c("bathy.bottom.depth_ln","thetao_ln","so_ln","river_input_ln")
var_combs <- list(vars_to_test) %>% append(combn(vars_to_test,3,simplify = F)) %>% 
  append(combn(vars_to_test,2,simplify = F)) %>% 
  append(unlist(vars_to_test))
```

```{r}
test_covariates_f1 <- function(v){
  f <- paste0("Ct~1+washed+",paste0("s(",v,",k=3)") %>% paste(collapse="+"))
  print(f)
  tic("Calculating ll:")
  f <- as.formula(f)
  fit <- try(sdmTMB_cv(
    formula=f,
    data = d_obs_filt,
    mesh = mesh,
    offset= "offsets_all",
    spatial="on",
    fold_ids=clust,
    family = stdcurve(),
    control = sdmTMBcontrol(stdcurve_df = d)
  ),
  silent=T)
  if(class(fit)=='try-error'){
    print(paste('Error.'))
    return(NA_real_)
  }
  # sanity checks
  # s <- map(fit$models,function(x)sanity(x)$all_ok)
  s <- sanity(fit$models[[1]])$all_ok
  if(any(s==FALSE)){
    print(paste('Error.'))
    return(NA_real_)
  } else{

    return(fit$fold_loglik[[1]])
  }
  toc()
}
test_covariates_f3 <- function(v){
  f <- paste0("Ct~1+washed+(1|yr_fct)+",paste0("s(",v,",k=3)") %>% paste(collapse="+"))
  print(f)
  tic("Calculating ll:")
  f <- as.formula(f)
  fit <- try(sdmTMB_cv(
    formula=f,
    data = d_obs_filt,
    mesh = mesh,
    offset= "offsets_all",
    spatial="on",
    fold_ids=clust,
    family = stdcurve(),
    control = sdmTMBcontrol(stdcurve_df = d)
  ),
  silent=T)
  if(class(fit)=='try-error'){
    print(paste('Error.'))
    return(NA_real_)
  }
  # sanity checks
  # s <- map(fit$models,function(x)sanity(x)$all_ok)
  s <- sanity(fit$models[[1]])$all_ok
  if(any(s==FALSE)){
    print(paste('Error.'))
    return(NA_real_)
  } else{
    
    return(fit$fold_loglik[[1]])
  }
  toc()
}

test_covariates_f4 <- function(v){
  f <- paste0("Ct~1+washed+(1|depth_cat)+(1|yr_fct)+",paste0("s(",v,",k=3)") %>% paste(collapse="+"))
  print(f)
  tic("Calculating ll:")
  f <- as.formula(f)
  fit <- try(sdmTMB_cv(
    formula=f,
    data = d_obs_filt,
    mesh = mesh,
    offset= "offsets_all",
    spatial="on",
    fold_ids=clust,
    family = stdcurve(),
    control = sdmTMBcontrol(stdcurve_df = d)
  ),
  silent=T)
  if(class(fit)=='try-error'){
    print(paste('Error.'))
    return(NA_real_)
  }
  # sanity checks
  # s <- map(fit$models,function(x)sanity(x)$all_ok)
  s <- sanity(fit$models[[1]])$all_ok
  if(any(s==FALSE)){
    print(paste('Error.'))
    return(NA_real_)
  } else{
    
    return(fit$fold_loglik[[1]])
  }
  toc()
}
```

Run the tests

```{r}
# for Model 1
f1_var_ll<-map_dbl(var_combs,test_covariates_f1)
# for Model 3
f3_var_ll<-map_dbl(var_combs,test_covariates_f3)
# for Model 4
f4_var_ll<-map_dbl(var_combs,test_covariates_f4)
```

```{r}
vsf1_p1 <- tibble(model_number=1:15,vars=var_combs,f1=f1_var_ll,f3=f3_var_ll,f4=f4_var_ll) %>% 
  pivot_longer(f1:f4,names_to="model_type",values_to = "ll") %>% 
  ggplot(aes(model_number,ll,color=model_type))+
  geom_point(size=3)
  geom_hline(yintercept=-310,linetype=2)+
  labs(x="Model Number",y="Sum LL")
vsf1_p1
```

The horizontal line in this plot indicates the original c-v log-likelihood of the temperature-only version of the simplest model. Only some of the variable selection models were higher-likelihood than this line. Interestingly, the "full" Model 4 that includes bathymetry, temperature, salinty, and river input was well-supported; but the "best" model according to this exercise is the temperature-only version of Model 3.

## Krill Variables

Do the same process as above, but choosing the temperature-only model and trying the krill variables one at a time.

```{r}
# Formulas to try (with different variables)
kvars_to_test <- paste0("k",1:6,"_ln")

kvars_combs <- map(kvars_to_test,~c(.,"thetao_ln"))

f1_kvar_ll<-map_dbl(kvars_combs,test_covariates_f1)
f3_kvar_ll<-map_dbl(kvars_combs,test_covariates_f3)
f4_kvar_ll<-map_dbl(kvars_combs,test_covariates_f4)

#plot
vs2_p <- tibble(model_number=1:6,vars=kvars_combs,f1=f1_kvar_ll,f3=f3_kvar_ll,f4=f4_kvar_ll) %>% 
  pivot_longer(f1:f4,names_to="model_type",values_to = "ll") %>% 
  ggplot(aes(model_number,ll,color=model_type))+
  geom_point(size=3)+
  geom_hline(yintercept=-306.5311,linetype=2)+
  labs(x="Model Number",y="Sum LL")
vs2_p
```

These actually improve our cross-validation likelihood values, particularly variables k3, k4, and k5. Now, the highest-likelihood model is Model 3, with `k4_ln` and `thetao_ln` as predictors.

# Chosen Model

Here is the final selected model and variables. We fit the final version of the model and then make output plots.

```{r}
tic("Fitting:")
m <- sdmTMB(
  Ct ~ 1+s(thetao_ln,k=3)+s(k4_ln,k=3)+washed+(1|yr_fct),
  data = d_obs_filt,
  mesh = mesh,
  offset= "offsets_all",
  spatial="on",
  spatiotemporal = "off",
  time=NULL,
  family = stdcurve(),
  control = sdmTMBcontrol(stdcurve_df = d)
)
toc()
m
make_pred_obs_plots(m,d,model_name="Model 1",saveplots = T,savetype = 'png')
```

## Conditional Plots

Choose temperature and k4; this is what the conditional effects look like in the chosen model.

```{r,fig.height=6,fig.width=4}
mconds_thetao <- plot_marginal(m,varname="thetao")
mconds_k4 <- plot_marginal(m,varname="k4")

mod1_covar_cond_effs <- cowplot::plot_grid(mconds_thetao,mconds_k4,nrow=2)
mod1_covar_cond_effs
```


# Index of Abundance

Let's just sum up the predictions by year to create an index of abundance. A simple sum should work relatively well here since we are using a regular prediction grid (i.e., all the spatial cells are the same area). We also can visualize this index in relation to river discharge

```{r}
m_abun <- make_abun_index(m)+theme(axis.text=element_text(size=12))
m_abun_lat <- make_lat_abundance(m,depth_integrate = T)+theme(axis.text=element_text(size=12))+xlim(35,50)

river_disc_p <- river_mean_discharge %>% 
  slice_max(order_by=discharge_mean,n=14) %>% 
  ggplot()+
  geom_col(aes(mouth_lat,discharge_mean))+
  labs(x="Latitude",y="Mean Discharge (m^3/s)",title="River Discharge")+
  coord_flip()+theme(axis.text=element_text(size=12))+xlim(35,50)

river_disc_p
m_abun_lat

lat_abun_river_disc_p <- plot_grid(m_abun_lat,river_disc_p,nrow=1,rel_widths=c(2,1),labels=c("a","b"))

lat_abun_river_disc_p
```

# Make Maps

We can make maps of predicted eulachon eDNA with our chosen model.

## Covariates Maps

Can also make maps of the covariates, just so we know what we're working with.

```{r,fig.height=10,fig.width=8}
thetao_plot <- make_map(grid.pred,thetao)+
    scale_fill_viridis(option="C")+
  labs(title="Temperature")
k4_plot <- make_map(grid.pred,log(k4))+
  scale_fill_viridis(option="C",na.value="grey90")+
  labs(title="Krill Metric 4 (log)")
thetao_plot
k4_plot
```

Spatial bounding boxes for different regions of the coast (for plotting)

```{r}
# if we want to zoom in on particular regions
gpsf <- grid.pred %>% st_as_sf(coords=c('x','y'),crs=pred.crs,remove=F)

# Oregon
orbbox <- coastcrop %>% filter(name=="Oregon") %>% st_bbox() %>% .[c(2,4)]
orbbox <- gpsf %>% filter(y>orbbox['ymin'],y<orbbox['ymax']) %>% st_bbox()

# Washington
wabbox <- coastcrop %>% filter(name=="Washington") %>% st_bbox()%>% .[c(2,4)]
wabbox <- gpsf %>% filter(y>wabbox['ymin'],y<wabbox['ymax']) %>% st_bbox()


# Washington and Oregon
wobbox <- coastcrop %>% filter(name%in%c("Washington","Oregon")) %>% st_bbox()%>% .[c(2,4)]
wobbox <- gpsf %>% filter(y>wobbox['ymin'],y<wobbox['ymax']) %>% st_bbox()

# california
cabbox <- coastcrop %>% filter(name=="California") %>% st_bbox()%>% .[c(2,4)]
cabbox <- gpsf %>% filter(y>cabbox['ymin'],y<cabbox['ymax']) %>% st_bbox()
```

## Spatial Predictions

Make spatial predictions with our selected model

```{r,fig.height=8,fig.width=8}
m.preds <- predict(m,newdata=grid.pred) %>% 
  mutate(expest=exp(est))

make_map(m.preds,est)+
    scale_fill_viridis(option="D")+
  labs(title="Model 1",fill="ln(eDNA)",x="",y="")+
  theme(axis.text.x=element_blank())

make_map(m.preds,est_non_rf)+ #tidy(m,'fixed')
    scale_fill_viridis(option="D")+
  labs(title="Model 1: Fixed Effects Only",fill="ln(eDNA)")

make_map(m.preds,est_rf)+ #tidy(m,'ran_pars')
    scale_fill_viridis(option="D")+
  labs(title="Model 1: Random Effects Only",fill="ln(eDNA)")

make_map_bathy(m.preds,est)+
    scale_fill_viridis(option="d")+
  labs(title="Model 1",fill="ln(eDNA)")

make_map_bathy(m.preds,est)+
    scale_fill_viridis(option="D")+
  labs(title="Model 1",fill="ln(eDNA)",x="",y="")+
  ylim(orbbox[c(2,4)])+xlim(orbbox[c(1,3)])

make_map_bathy(m.preds,est)+
    scale_fill_viridis(option="D")+
  labs(title="Model 1",fill="ln(eDNA)",x="",y="")+
  ylim(wabbox[c(2,4)])+xlim(wabbox[c(1,3)])

make_map_bathy(m.preds,est)+
    scale_fill_viridis(option="D")+
  labs(title="",fill="ln(eDNA)",x="",y="")+
  ylim(wobbox[c(2,4)])+xlim(wobbox[c(1,3)])+
  coord_sf(datum=NA)

make_map_bathy(m.preds,est)+
    scale_fill_viridis(option="D")+
  labs(title="Model 1",fill="ln(eDNA)",x="",y="")+
  ylim(cabbox[c(2,4)])+xlim(cabbox[c(1,3)])

# quantiles instead of log copies
m.preds %>% 
  arrange(est) %>% 
  mutate(quantest=percent_rank(est)*100) %>% 
  make_map_bathy(quantest)+
  ylim(wobbox[c(2,4)])+xlim(wobbox[c(1,3)])+
  scale_fill_viridis(option='D',discrete=F)+
    # scale_fill_manual(breaks=seq(0,1,by=0.1),values=viridis_pal(option="C")(11))+
  labs(title="Model 1",fill="Quantile (eDNA)")

#presence/absence only
m.pa.map <- make_presence_absence_map(m)[[2]]+labs(x="",y="")+
  ylim(wobbox[c(2,4)])+xlim(wobbox[c(1,3)])
```

# Test Mesh Complexity

One thing that seems to have an effect on our fits is the configuration of the INLA mesh, particularly its complexity, or number of knots. Meshes that are too complex can make pretty maps, but we run the risk of overfitting. As a general rule of thumb, we want to pick a less complex mesh, but one that still allows us to make good predictions. Let's see if we can use cross-validation likelihoods to assess which mesh to use.

```{r}
cutoffs_to_try = seq(10,160,by=10)
meshestest <- map(cutoffs_to_try,function(cuts) make_mesh(d_obs_filt,xy_cols=c('utm.lon.km','utm.lat.km'),type='cutoff',cutoff=cuts))
```

Now try to fit the same model on each mesh. Because we've noticed a tradeoff in covariate number and mesh complexity (including lots of non-convergence if a mesh is too complex combined with many predictors), we test this with a model that includes 3 environmental covariates.

```{r}
# Function to run a model using a candidate mesh
calc_mesh_ll <- function(testmesh){
  meshn=testmesh$mesh$n
  fit <- try(sdmTMB_cv(
    Ct ~ 1+washed+s(thetao_ln,k=3)+s(bathy.bottom.depth_ln,k=3)+s(k5_ln,k=3),
    data = d_obs_filt,
    mesh = testmesh,
    offset= "offsets_all",
    spatial="on",
    fold_ids=clust,
    family = stdcurve(),
    control = sdmTMBcontrol(stdcurve_df = d)
  ),
  silent=T)
  if(class(fit)=='try-error'){
    print(paste('Error.'))
    return(NA_real_)
  }
  # sanity checks
  # s <- map(fit$models,function(x)sanity(x)$all_ok)
  s <- sanity(fit$models[[1]])$all_ok
  if(any(s==FALSE)){
    print(paste("ERROR: Mesh with", meshn,'vertices had issues.'))
    return(NA_real_)
  } else{
    print(paste("Mesh with", meshn, "vertices worked."))

    return(fit$fold_loglik[[1]])
  }
}
```


```{r}
# now, test the meshes
tic("CV mesh analysis")
meshes.ll.test <- map_dbl(meshestest,calc_mesh_ll)
toc()
```

Plot the relationship between mesh complexity and the 3-fold CV likelihood. Knots is one way to measure, but there's also total vertices (`mesh$mesh$n`)

```{r}
mesh.comparison <- tibble(cutoff=cutoffs_to_try,sumll=meshes.ll.test) %>% 
  ggplot(aes(cutoff,sumll))+
  geom_line()+
  geom_point()+
  # stat_smooth(method = "lm", formula = y ~ x + I(x^2), size = 1,se=F)+
  geom_smooth(se=F)+
  labs(x="Minimum Interior Edge Length",y="Summed Log Likelihood")
mesh.comparison

mesh.comparison2 <- tibble(cutoff=cutoffs_to_try,sumll=meshes.ll.test) %>% 
  mutate(nverts=map_dbl(meshestest,~.$mesh$n)) %>% 
  ggplot(aes(nverts,sumll))+
  geom_line()+
  geom_point()+
  geom_smooth(se=F)+
  # stat_smooth(method = "lm", formula = y ~ x + I(x^2), size = 1,se=F)+
  # scale_x_continuous(limits=c(100,400),breaks=seq(100,400,by=100))+
  labs(x="Number of Vertices",y="Summed Log Likelihood")
mesh.comparison2

meshes_table <- tibble(cutoff=cutoffs_to_try,sumll=meshes.ll.test) %>% 
  mutate(nverts=map_dbl(meshestest,~.$mesh$n))

meshes.edges.nverts <- meshes_table%>% 
  ggplot(aes(cutoff,nverts))+
  # geom_line()+
  geom_point()+
  labs(y="Number of Vertices",x="Minimum Interior Edge Length")

meshes.p <-plot_grid(mesh.comparison,mesh.comparison2,nrow=1)

meshes.edges.nverts
meshes.p

# ggsave(here('plots','mesh_complexity_test.png'),meshes.p,h=4,w=7,bg='white')
```

After testing multiple meshes with models of different complexity in covariates, it seems that the mesh with 118 knots and a cutoff (minimum interior edge length) of 40km works well for both simple and slightly more complex models, and therefore represents a balance of our needs here. We choose to move forward with this mesh.
